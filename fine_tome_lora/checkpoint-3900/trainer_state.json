{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.312,
  "eval_steps": 500,
  "global_step": 3900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008,
      "grad_norm": 0.2531868815422058,
      "learning_rate": 9e-05,
      "loss": 0.869,
      "step": 10
    },
    {
      "epoch": 0.0016,
      "grad_norm": 0.1930529624223709,
      "learning_rate": 0.00019,
      "loss": 0.8863,
      "step": 20
    },
    {
      "epoch": 0.0024,
      "grad_norm": 0.1917732059955597,
      "learning_rate": 0.00019954773869346735,
      "loss": 0.8657,
      "step": 30
    },
    {
      "epoch": 0.0032,
      "grad_norm": 0.16848419606685638,
      "learning_rate": 0.00019904522613065328,
      "loss": 0.7683,
      "step": 40
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.1739313304424286,
      "learning_rate": 0.00019854271356783921,
      "loss": 0.8471,
      "step": 50
    },
    {
      "epoch": 0.0048,
      "grad_norm": 0.19584374129772186,
      "learning_rate": 0.00019804020100502515,
      "loss": 0.8749,
      "step": 60
    },
    {
      "epoch": 0.0056,
      "grad_norm": 0.1760822832584381,
      "learning_rate": 0.00019753768844221105,
      "loss": 0.8577,
      "step": 70
    },
    {
      "epoch": 0.0064,
      "grad_norm": 0.20022426545619965,
      "learning_rate": 0.00019703517587939698,
      "loss": 0.8109,
      "step": 80
    },
    {
      "epoch": 0.0072,
      "grad_norm": 0.15878379344940186,
      "learning_rate": 0.00019653266331658294,
      "loss": 0.8253,
      "step": 90
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.17008709907531738,
      "learning_rate": 0.00019603015075376885,
      "loss": 0.6997,
      "step": 100
    },
    {
      "epoch": 0.0088,
      "grad_norm": 0.20923598110675812,
      "learning_rate": 0.00019552763819095478,
      "loss": 0.7939,
      "step": 110
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.1741296499967575,
      "learning_rate": 0.0001950251256281407,
      "loss": 0.7477,
      "step": 120
    },
    {
      "epoch": 0.0104,
      "grad_norm": 0.16154296696186066,
      "learning_rate": 0.00019452261306532665,
      "loss": 0.7427,
      "step": 130
    },
    {
      "epoch": 0.0112,
      "grad_norm": 0.2291286736726761,
      "learning_rate": 0.00019402010050251258,
      "loss": 0.6523,
      "step": 140
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.1941831111907959,
      "learning_rate": 0.00019351758793969848,
      "loss": 0.7662,
      "step": 150
    },
    {
      "epoch": 0.0128,
      "grad_norm": 0.21034204959869385,
      "learning_rate": 0.00019301507537688444,
      "loss": 0.7873,
      "step": 160
    },
    {
      "epoch": 0.0136,
      "grad_norm": 0.21251195669174194,
      "learning_rate": 0.00019251256281407035,
      "loss": 0.7792,
      "step": 170
    },
    {
      "epoch": 0.0144,
      "grad_norm": 0.1886621117591858,
      "learning_rate": 0.00019201005025125628,
      "loss": 0.813,
      "step": 180
    },
    {
      "epoch": 0.0152,
      "grad_norm": 0.1745106428861618,
      "learning_rate": 0.00019150753768844224,
      "loss": 0.7934,
      "step": 190
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.16657336056232452,
      "learning_rate": 0.00019100502512562815,
      "loss": 0.7125,
      "step": 200
    },
    {
      "epoch": 0.0168,
      "grad_norm": 0.23261137306690216,
      "learning_rate": 0.00019050251256281408,
      "loss": 0.6811,
      "step": 210
    },
    {
      "epoch": 0.0176,
      "grad_norm": 0.16586744785308838,
      "learning_rate": 0.00019,
      "loss": 0.8428,
      "step": 220
    },
    {
      "epoch": 0.0184,
      "grad_norm": 0.17755423486232758,
      "learning_rate": 0.00018949748743718594,
      "loss": 0.7289,
      "step": 230
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.17322957515716553,
      "learning_rate": 0.00018899497487437188,
      "loss": 0.7794,
      "step": 240
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20243531465530396,
      "learning_rate": 0.00018849246231155778,
      "loss": 0.7786,
      "step": 250
    },
    {
      "epoch": 0.0208,
      "grad_norm": 0.18073731660842896,
      "learning_rate": 0.00018798994974874374,
      "loss": 0.8049,
      "step": 260
    },
    {
      "epoch": 0.0216,
      "grad_norm": 0.1702076941728592,
      "learning_rate": 0.00018748743718592965,
      "loss": 0.7226,
      "step": 270
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.22883698344230652,
      "learning_rate": 0.00018698492462311558,
      "loss": 0.71,
      "step": 280
    },
    {
      "epoch": 0.0232,
      "grad_norm": 0.16316096484661102,
      "learning_rate": 0.00018648241206030154,
      "loss": 0.7073,
      "step": 290
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.2177870124578476,
      "learning_rate": 0.00018597989949748744,
      "loss": 0.825,
      "step": 300
    },
    {
      "epoch": 0.0248,
      "grad_norm": 0.18085099756717682,
      "learning_rate": 0.00018547738693467338,
      "loss": 0.7102,
      "step": 310
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.22183635830879211,
      "learning_rate": 0.0001849748743718593,
      "loss": 0.758,
      "step": 320
    },
    {
      "epoch": 0.0264,
      "grad_norm": 0.1532890498638153,
      "learning_rate": 0.00018447236180904524,
      "loss": 0.7288,
      "step": 330
    },
    {
      "epoch": 0.0272,
      "grad_norm": 0.1831154227256775,
      "learning_rate": 0.00018396984924623117,
      "loss": 0.6848,
      "step": 340
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.1726095974445343,
      "learning_rate": 0.00018346733668341708,
      "loss": 0.7302,
      "step": 350
    },
    {
      "epoch": 0.0288,
      "grad_norm": 0.1842663437128067,
      "learning_rate": 0.00018296482412060304,
      "loss": 0.6922,
      "step": 360
    },
    {
      "epoch": 0.0296,
      "grad_norm": 0.23682256042957306,
      "learning_rate": 0.00018246231155778894,
      "loss": 0.7198,
      "step": 370
    },
    {
      "epoch": 0.0304,
      "grad_norm": 0.20753951370716095,
      "learning_rate": 0.00018195979899497487,
      "loss": 0.7267,
      "step": 380
    },
    {
      "epoch": 0.0312,
      "grad_norm": 0.19004715979099274,
      "learning_rate": 0.00018145728643216083,
      "loss": 0.756,
      "step": 390
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.1914864331483841,
      "learning_rate": 0.00018095477386934674,
      "loss": 0.7631,
      "step": 400
    },
    {
      "epoch": 0.0328,
      "grad_norm": 0.22531437873840332,
      "learning_rate": 0.00018045226130653267,
      "loss": 0.7929,
      "step": 410
    },
    {
      "epoch": 0.0336,
      "grad_norm": 0.2130584716796875,
      "learning_rate": 0.0001799497487437186,
      "loss": 0.7371,
      "step": 420
    },
    {
      "epoch": 0.0344,
      "grad_norm": 0.2222171574831009,
      "learning_rate": 0.00017944723618090454,
      "loss": 0.7252,
      "step": 430
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.1589411199092865,
      "learning_rate": 0.00017894472361809047,
      "loss": 0.7068,
      "step": 440
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.16206365823745728,
      "learning_rate": 0.00017844221105527637,
      "loss": 0.7953,
      "step": 450
    },
    {
      "epoch": 0.0368,
      "grad_norm": 0.19581696391105652,
      "learning_rate": 0.00017793969849246233,
      "loss": 0.8085,
      "step": 460
    },
    {
      "epoch": 0.0376,
      "grad_norm": 0.24267448484897614,
      "learning_rate": 0.00017743718592964824,
      "loss": 0.744,
      "step": 470
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.2054692804813385,
      "learning_rate": 0.00017693467336683417,
      "loss": 0.761,
      "step": 480
    },
    {
      "epoch": 0.0392,
      "grad_norm": 0.22304122149944305,
      "learning_rate": 0.00017643216080402013,
      "loss": 0.6568,
      "step": 490
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.19095240533351898,
      "learning_rate": 0.00017592964824120604,
      "loss": 0.7082,
      "step": 500
    },
    {
      "epoch": 0.0408,
      "grad_norm": 0.22236813604831696,
      "learning_rate": 0.00017542713567839197,
      "loss": 0.632,
      "step": 510
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.19071394205093384,
      "learning_rate": 0.0001749246231155779,
      "loss": 0.7092,
      "step": 520
    },
    {
      "epoch": 0.0424,
      "grad_norm": 0.16349796950817108,
      "learning_rate": 0.00017442211055276383,
      "loss": 0.776,
      "step": 530
    },
    {
      "epoch": 0.0432,
      "grad_norm": 0.22489053010940552,
      "learning_rate": 0.00017391959798994977,
      "loss": 0.7412,
      "step": 540
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.26592934131622314,
      "learning_rate": 0.00017341708542713567,
      "loss": 0.7852,
      "step": 550
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.21319791674613953,
      "learning_rate": 0.00017291457286432163,
      "loss": 0.7678,
      "step": 560
    },
    {
      "epoch": 0.0456,
      "grad_norm": 0.2440304458141327,
      "learning_rate": 0.00017241206030150754,
      "loss": 0.727,
      "step": 570
    },
    {
      "epoch": 0.0464,
      "grad_norm": 0.16619427502155304,
      "learning_rate": 0.00017190954773869347,
      "loss": 0.7465,
      "step": 580
    },
    {
      "epoch": 0.0472,
      "grad_norm": 0.23365558683872223,
      "learning_rate": 0.00017140703517587943,
      "loss": 0.723,
      "step": 590
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.19429318606853485,
      "learning_rate": 0.00017090452261306533,
      "loss": 0.766,
      "step": 600
    },
    {
      "epoch": 0.0488,
      "grad_norm": 0.19211529195308685,
      "learning_rate": 0.00017040201005025127,
      "loss": 0.7619,
      "step": 610
    },
    {
      "epoch": 0.0496,
      "grad_norm": 0.22238893806934357,
      "learning_rate": 0.0001698994974874372,
      "loss": 0.7179,
      "step": 620
    },
    {
      "epoch": 0.0504,
      "grad_norm": 0.18008515238761902,
      "learning_rate": 0.00016939698492462313,
      "loss": 0.7284,
      "step": 630
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.17934571206569672,
      "learning_rate": 0.00016889447236180906,
      "loss": 0.689,
      "step": 640
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.2014516294002533,
      "learning_rate": 0.00016839195979899497,
      "loss": 0.6321,
      "step": 650
    },
    {
      "epoch": 0.0528,
      "grad_norm": 0.1943223923444748,
      "learning_rate": 0.00016788944723618093,
      "loss": 0.6751,
      "step": 660
    },
    {
      "epoch": 0.0536,
      "grad_norm": 0.2581653892993927,
      "learning_rate": 0.00016738693467336683,
      "loss": 0.7823,
      "step": 670
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.19756485521793365,
      "learning_rate": 0.00016688442211055277,
      "loss": 0.8237,
      "step": 680
    },
    {
      "epoch": 0.0552,
      "grad_norm": 0.19730517268180847,
      "learning_rate": 0.00016638190954773873,
      "loss": 0.753,
      "step": 690
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.20256008207798004,
      "learning_rate": 0.00016587939698492463,
      "loss": 0.7383,
      "step": 700
    },
    {
      "epoch": 0.0568,
      "grad_norm": 0.18425288796424866,
      "learning_rate": 0.00016537688442211056,
      "loss": 0.735,
      "step": 710
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.2603738307952881,
      "learning_rate": 0.0001648743718592965,
      "loss": 0.7238,
      "step": 720
    },
    {
      "epoch": 0.0584,
      "grad_norm": 0.19051654636859894,
      "learning_rate": 0.00016437185929648243,
      "loss": 0.7722,
      "step": 730
    },
    {
      "epoch": 0.0592,
      "grad_norm": 0.26497745513916016,
      "learning_rate": 0.00016386934673366833,
      "loss": 0.7849,
      "step": 740
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.20511578023433685,
      "learning_rate": 0.00016336683417085427,
      "loss": 0.7508,
      "step": 750
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.21514882147312164,
      "learning_rate": 0.00016286432160804023,
      "loss": 0.6899,
      "step": 760
    },
    {
      "epoch": 0.0616,
      "grad_norm": 0.21036550402641296,
      "learning_rate": 0.00016236180904522613,
      "loss": 0.7711,
      "step": 770
    },
    {
      "epoch": 0.0624,
      "grad_norm": 0.22382286190986633,
      "learning_rate": 0.00016185929648241206,
      "loss": 0.7396,
      "step": 780
    },
    {
      "epoch": 0.0632,
      "grad_norm": 0.25567954778671265,
      "learning_rate": 0.000161356783919598,
      "loss": 0.7815,
      "step": 790
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.19237756729125977,
      "learning_rate": 0.00016085427135678393,
      "loss": 0.754,
      "step": 800
    },
    {
      "epoch": 0.0648,
      "grad_norm": 0.17646832764148712,
      "learning_rate": 0.00016035175879396986,
      "loss": 0.7173,
      "step": 810
    },
    {
      "epoch": 0.0656,
      "grad_norm": 0.19630268216133118,
      "learning_rate": 0.0001598492462311558,
      "loss": 0.7711,
      "step": 820
    },
    {
      "epoch": 0.0664,
      "grad_norm": 0.18746444582939148,
      "learning_rate": 0.00015934673366834173,
      "loss": 0.7183,
      "step": 830
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.20779049396514893,
      "learning_rate": 0.00015884422110552763,
      "loss": 0.6416,
      "step": 840
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.20880575478076935,
      "learning_rate": 0.00015834170854271356,
      "loss": 0.7059,
      "step": 850
    },
    {
      "epoch": 0.0688,
      "grad_norm": 0.24178797006607056,
      "learning_rate": 0.00015783919597989952,
      "loss": 0.7543,
      "step": 860
    },
    {
      "epoch": 0.0696,
      "grad_norm": 0.18807928264141083,
      "learning_rate": 0.00015733668341708543,
      "loss": 0.6927,
      "step": 870
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.22505849599838257,
      "learning_rate": 0.00015683417085427136,
      "loss": 0.7337,
      "step": 880
    },
    {
      "epoch": 0.0712,
      "grad_norm": 0.20205721259117126,
      "learning_rate": 0.0001563316582914573,
      "loss": 0.7184,
      "step": 890
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.21385632455348969,
      "learning_rate": 0.00015582914572864323,
      "loss": 0.6309,
      "step": 900
    },
    {
      "epoch": 0.0728,
      "grad_norm": 0.22321712970733643,
      "learning_rate": 0.00015532663316582916,
      "loss": 0.7062,
      "step": 910
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.1859116107225418,
      "learning_rate": 0.0001548241206030151,
      "loss": 0.7208,
      "step": 920
    },
    {
      "epoch": 0.0744,
      "grad_norm": 0.21318915486335754,
      "learning_rate": 0.00015432160804020102,
      "loss": 0.762,
      "step": 930
    },
    {
      "epoch": 0.0752,
      "grad_norm": 0.24362994730472565,
      "learning_rate": 0.00015381909547738693,
      "loss": 0.7543,
      "step": 940
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.20013615489006042,
      "learning_rate": 0.00015331658291457286,
      "loss": 0.7193,
      "step": 950
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.1809784322977066,
      "learning_rate": 0.00015281407035175882,
      "loss": 0.7235,
      "step": 960
    },
    {
      "epoch": 0.0776,
      "grad_norm": 0.20783551037311554,
      "learning_rate": 0.00015231155778894472,
      "loss": 0.6777,
      "step": 970
    },
    {
      "epoch": 0.0784,
      "grad_norm": 0.23246368765830994,
      "learning_rate": 0.00015180904522613066,
      "loss": 0.7608,
      "step": 980
    },
    {
      "epoch": 0.0792,
      "grad_norm": 0.18310409784317017,
      "learning_rate": 0.0001513065326633166,
      "loss": 0.7966,
      "step": 990
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.21902886033058167,
      "learning_rate": 0.00015080402010050252,
      "loss": 0.6844,
      "step": 1000
    },
    {
      "epoch": 0.0808,
      "grad_norm": 0.2550423741340637,
      "learning_rate": 0.00015030150753768845,
      "loss": 0.7981,
      "step": 1010
    },
    {
      "epoch": 0.0816,
      "grad_norm": 0.20205308496952057,
      "learning_rate": 0.0001497989949748744,
      "loss": 0.7525,
      "step": 1020
    },
    {
      "epoch": 0.0824,
      "grad_norm": 0.21554160118103027,
      "learning_rate": 0.00014929648241206032,
      "loss": 0.6824,
      "step": 1030
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.2011314183473587,
      "learning_rate": 0.00014879396984924622,
      "loss": 0.804,
      "step": 1040
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.1901412457227707,
      "learning_rate": 0.00014829145728643216,
      "loss": 0.7297,
      "step": 1050
    },
    {
      "epoch": 0.0848,
      "grad_norm": 0.2805059850215912,
      "learning_rate": 0.00014778894472361812,
      "loss": 0.7924,
      "step": 1060
    },
    {
      "epoch": 0.0856,
      "grad_norm": 0.2284371256828308,
      "learning_rate": 0.00014728643216080402,
      "loss": 0.7717,
      "step": 1070
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.19287917017936707,
      "learning_rate": 0.00014678391959798995,
      "loss": 0.7099,
      "step": 1080
    },
    {
      "epoch": 0.0872,
      "grad_norm": 0.2082740068435669,
      "learning_rate": 0.0001462814070351759,
      "loss": 0.707,
      "step": 1090
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.25035178661346436,
      "learning_rate": 0.00014577889447236182,
      "loss": 0.7104,
      "step": 1100
    },
    {
      "epoch": 0.0888,
      "grad_norm": 0.21876747906208038,
      "learning_rate": 0.00014527638190954775,
      "loss": 0.7167,
      "step": 1110
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.20393097400665283,
      "learning_rate": 0.00014477386934673366,
      "loss": 0.7091,
      "step": 1120
    },
    {
      "epoch": 0.0904,
      "grad_norm": 0.23459255695343018,
      "learning_rate": 0.00014427135678391962,
      "loss": 0.6882,
      "step": 1130
    },
    {
      "epoch": 0.0912,
      "grad_norm": 0.1962691694498062,
      "learning_rate": 0.00014376884422110552,
      "loss": 0.745,
      "step": 1140
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.16016069054603577,
      "learning_rate": 0.00014326633165829145,
      "loss": 0.7195,
      "step": 1150
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.17656801640987396,
      "learning_rate": 0.00014276381909547741,
      "loss": 0.7312,
      "step": 1160
    },
    {
      "epoch": 0.0936,
      "grad_norm": 0.2010076493024826,
      "learning_rate": 0.00014226130653266332,
      "loss": 0.7149,
      "step": 1170
    },
    {
      "epoch": 0.0944,
      "grad_norm": 0.20656391978263855,
      "learning_rate": 0.00014175879396984925,
      "loss": 0.7361,
      "step": 1180
    },
    {
      "epoch": 0.0952,
      "grad_norm": 0.26269474625587463,
      "learning_rate": 0.00014125628140703518,
      "loss": 0.775,
      "step": 1190
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.2505725026130676,
      "learning_rate": 0.00014075376884422112,
      "loss": 0.8689,
      "step": 1200
    },
    {
      "epoch": 0.0968,
      "grad_norm": 0.2484322488307953,
      "learning_rate": 0.00014025125628140705,
      "loss": 0.6871,
      "step": 1210
    },
    {
      "epoch": 0.0976,
      "grad_norm": 0.19582174718379974,
      "learning_rate": 0.00013974874371859295,
      "loss": 0.6763,
      "step": 1220
    },
    {
      "epoch": 0.0984,
      "grad_norm": 0.23105379939079285,
      "learning_rate": 0.0001392462311557789,
      "loss": 0.7164,
      "step": 1230
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.18418265879154205,
      "learning_rate": 0.00013874371859296482,
      "loss": 0.6841,
      "step": 1240
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.22285601496696472,
      "learning_rate": 0.00013824120603015075,
      "loss": 0.7373,
      "step": 1250
    },
    {
      "epoch": 0.1008,
      "grad_norm": 0.24483215808868408,
      "learning_rate": 0.0001377386934673367,
      "loss": 0.7544,
      "step": 1260
    },
    {
      "epoch": 0.1016,
      "grad_norm": 0.23733611404895782,
      "learning_rate": 0.00013723618090452262,
      "loss": 0.6279,
      "step": 1270
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.29949432611465454,
      "learning_rate": 0.00013673366834170855,
      "loss": 0.7381,
      "step": 1280
    },
    {
      "epoch": 0.1032,
      "grad_norm": 0.1718859076499939,
      "learning_rate": 0.00013623115577889448,
      "loss": 0.7109,
      "step": 1290
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.3000914752483368,
      "learning_rate": 0.0001357286432160804,
      "loss": 0.7854,
      "step": 1300
    },
    {
      "epoch": 0.1048,
      "grad_norm": 0.2271508127450943,
      "learning_rate": 0.00013522613065326635,
      "loss": 0.7692,
      "step": 1310
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.19870683550834656,
      "learning_rate": 0.00013472361809045225,
      "loss": 0.7007,
      "step": 1320
    },
    {
      "epoch": 0.1064,
      "grad_norm": 0.22137877345085144,
      "learning_rate": 0.0001342211055276382,
      "loss": 0.7298,
      "step": 1330
    },
    {
      "epoch": 0.1072,
      "grad_norm": 0.3146408796310425,
      "learning_rate": 0.00013371859296482412,
      "loss": 0.7606,
      "step": 1340
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.21241314709186554,
      "learning_rate": 0.00013321608040201005,
      "loss": 0.7501,
      "step": 1350
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.22661982476711273,
      "learning_rate": 0.000132713567839196,
      "loss": 0.7336,
      "step": 1360
    },
    {
      "epoch": 0.1096,
      "grad_norm": 0.2269732505083084,
      "learning_rate": 0.0001322110552763819,
      "loss": 0.6577,
      "step": 1370
    },
    {
      "epoch": 0.1104,
      "grad_norm": 0.20453964173793793,
      "learning_rate": 0.00013170854271356785,
      "loss": 0.5858,
      "step": 1380
    },
    {
      "epoch": 0.1112,
      "grad_norm": 0.21968919038772583,
      "learning_rate": 0.00013120603015075378,
      "loss": 0.8289,
      "step": 1390
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.28466612100601196,
      "learning_rate": 0.0001307035175879397,
      "loss": 0.6557,
      "step": 1400
    },
    {
      "epoch": 0.1128,
      "grad_norm": 0.2434697151184082,
      "learning_rate": 0.00013020100502512564,
      "loss": 0.7098,
      "step": 1410
    },
    {
      "epoch": 0.1136,
      "grad_norm": 0.21337658166885376,
      "learning_rate": 0.00012969849246231155,
      "loss": 0.7076,
      "step": 1420
    },
    {
      "epoch": 0.1144,
      "grad_norm": 0.23271609842777252,
      "learning_rate": 0.0001291959798994975,
      "loss": 0.659,
      "step": 1430
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.17638632655143738,
      "learning_rate": 0.0001286934673366834,
      "loss": 0.7251,
      "step": 1440
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.210876926779747,
      "learning_rate": 0.00012819095477386935,
      "loss": 0.6926,
      "step": 1450
    },
    {
      "epoch": 0.1168,
      "grad_norm": 0.21036916971206665,
      "learning_rate": 0.0001276884422110553,
      "loss": 0.641,
      "step": 1460
    },
    {
      "epoch": 0.1176,
      "grad_norm": 0.19564253091812134,
      "learning_rate": 0.0001271859296482412,
      "loss": 0.6725,
      "step": 1470
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.23247991502285004,
      "learning_rate": 0.00012668341708542714,
      "loss": 0.7136,
      "step": 1480
    },
    {
      "epoch": 0.1192,
      "grad_norm": 0.2630729377269745,
      "learning_rate": 0.00012618090452261307,
      "loss": 0.7077,
      "step": 1490
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.20902033150196075,
      "learning_rate": 0.000125678391959799,
      "loss": 0.6361,
      "step": 1500
    },
    {
      "epoch": 0.1208,
      "grad_norm": 0.2789543867111206,
      "learning_rate": 0.00012517587939698494,
      "loss": 0.7666,
      "step": 1510
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.18507817387580872,
      "learning_rate": 0.00012467336683417085,
      "loss": 0.7605,
      "step": 1520
    },
    {
      "epoch": 0.1224,
      "grad_norm": 0.1959555745124817,
      "learning_rate": 0.0001241708542713568,
      "loss": 0.6666,
      "step": 1530
    },
    {
      "epoch": 0.1232,
      "grad_norm": 0.24794399738311768,
      "learning_rate": 0.0001236683417085427,
      "loss": 0.7683,
      "step": 1540
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.19740252196788788,
      "learning_rate": 0.00012316582914572864,
      "loss": 0.7363,
      "step": 1550
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.26821744441986084,
      "learning_rate": 0.0001226633165829146,
      "loss": 0.7383,
      "step": 1560
    },
    {
      "epoch": 0.1256,
      "grad_norm": 0.26557180285453796,
      "learning_rate": 0.0001221608040201005,
      "loss": 0.7577,
      "step": 1570
    },
    {
      "epoch": 0.1264,
      "grad_norm": 0.2674664855003357,
      "learning_rate": 0.00012165829145728644,
      "loss": 0.7583,
      "step": 1580
    },
    {
      "epoch": 0.1272,
      "grad_norm": 0.20231027901172638,
      "learning_rate": 0.00012115577889447236,
      "loss": 0.6982,
      "step": 1590
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.1999797523021698,
      "learning_rate": 0.0001206532663316583,
      "loss": 0.7304,
      "step": 1600
    },
    {
      "epoch": 0.1288,
      "grad_norm": 0.22823630273342133,
      "learning_rate": 0.00012015075376884424,
      "loss": 0.7158,
      "step": 1610
    },
    {
      "epoch": 0.1296,
      "grad_norm": 0.18305253982543945,
      "learning_rate": 0.00011964824120603016,
      "loss": 0.6936,
      "step": 1620
    },
    {
      "epoch": 0.1304,
      "grad_norm": 0.23361815512180328,
      "learning_rate": 0.00011914572864321609,
      "loss": 0.755,
      "step": 1630
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.2231806516647339,
      "learning_rate": 0.00011864321608040201,
      "loss": 0.6854,
      "step": 1640
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.2374042272567749,
      "learning_rate": 0.00011814070351758795,
      "loss": 0.7697,
      "step": 1650
    },
    {
      "epoch": 0.1328,
      "grad_norm": 0.2575065493583679,
      "learning_rate": 0.00011763819095477389,
      "loss": 0.7633,
      "step": 1660
    },
    {
      "epoch": 0.1336,
      "grad_norm": 0.21743933856487274,
      "learning_rate": 0.0001171356783919598,
      "loss": 0.6971,
      "step": 1670
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.23204030096530914,
      "learning_rate": 0.00011663316582914574,
      "loss": 0.7848,
      "step": 1680
    },
    {
      "epoch": 0.1352,
      "grad_norm": 0.27709147334098816,
      "learning_rate": 0.00011613065326633166,
      "loss": 0.733,
      "step": 1690
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.19341585040092468,
      "learning_rate": 0.0001156281407035176,
      "loss": 0.7265,
      "step": 1700
    },
    {
      "epoch": 0.1368,
      "grad_norm": 0.20780795812606812,
      "learning_rate": 0.00011512562814070353,
      "loss": 0.6862,
      "step": 1710
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.3379129469394684,
      "learning_rate": 0.00011462311557788945,
      "loss": 0.7173,
      "step": 1720
    },
    {
      "epoch": 0.1384,
      "grad_norm": 0.22132007777690887,
      "learning_rate": 0.00011412060301507539,
      "loss": 0.7461,
      "step": 1730
    },
    {
      "epoch": 0.1392,
      "grad_norm": 0.2263982594013214,
      "learning_rate": 0.0001136180904522613,
      "loss": 0.7089,
      "step": 1740
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.21557007730007172,
      "learning_rate": 0.00011311557788944725,
      "loss": 0.6772,
      "step": 1750
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.19785411655902863,
      "learning_rate": 0.00011261306532663316,
      "loss": 0.7101,
      "step": 1760
    },
    {
      "epoch": 0.1416,
      "grad_norm": 0.2100037932395935,
      "learning_rate": 0.0001121105527638191,
      "loss": 0.7253,
      "step": 1770
    },
    {
      "epoch": 0.1424,
      "grad_norm": 0.19375765323638916,
      "learning_rate": 0.00011160804020100503,
      "loss": 0.7182,
      "step": 1780
    },
    {
      "epoch": 0.1432,
      "grad_norm": 0.20379994809627533,
      "learning_rate": 0.00011110552763819095,
      "loss": 0.7182,
      "step": 1790
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.2227432280778885,
      "learning_rate": 0.0001106030150753769,
      "loss": 0.7134,
      "step": 1800
    },
    {
      "epoch": 0.1448,
      "grad_norm": 0.2234100103378296,
      "learning_rate": 0.0001101005025125628,
      "loss": 0.7507,
      "step": 1810
    },
    {
      "epoch": 0.1456,
      "grad_norm": 0.21250960230827332,
      "learning_rate": 0.00010959798994974875,
      "loss": 0.7525,
      "step": 1820
    },
    {
      "epoch": 0.1464,
      "grad_norm": 0.22364011406898499,
      "learning_rate": 0.00010909547738693468,
      "loss": 0.7581,
      "step": 1830
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.23716668784618378,
      "learning_rate": 0.0001085929648241206,
      "loss": 0.7748,
      "step": 1840
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.24673661589622498,
      "learning_rate": 0.00010809045226130655,
      "loss": 0.7154,
      "step": 1850
    },
    {
      "epoch": 0.1488,
      "grad_norm": 0.22557051479816437,
      "learning_rate": 0.00010758793969849245,
      "loss": 0.7026,
      "step": 1860
    },
    {
      "epoch": 0.1496,
      "grad_norm": 0.21108154952526093,
      "learning_rate": 0.0001070854271356784,
      "loss": 0.733,
      "step": 1870
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.18239650130271912,
      "learning_rate": 0.00010658291457286433,
      "loss": 0.7341,
      "step": 1880
    },
    {
      "epoch": 0.1512,
      "grad_norm": 0.2088952511548996,
      "learning_rate": 0.00010608040201005025,
      "loss": 0.7263,
      "step": 1890
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.3308855891227722,
      "learning_rate": 0.0001055778894472362,
      "loss": 0.7053,
      "step": 1900
    },
    {
      "epoch": 0.1528,
      "grad_norm": 0.23010236024856567,
      "learning_rate": 0.0001050753768844221,
      "loss": 0.7265,
      "step": 1910
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.20500542223453522,
      "learning_rate": 0.00010457286432160805,
      "loss": 0.6761,
      "step": 1920
    },
    {
      "epoch": 0.1544,
      "grad_norm": 0.19762028753757477,
      "learning_rate": 0.00010407035175879398,
      "loss": 0.8036,
      "step": 1930
    },
    {
      "epoch": 0.1552,
      "grad_norm": 0.19774429500102997,
      "learning_rate": 0.0001035678391959799,
      "loss": 0.7816,
      "step": 1940
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.22216489911079407,
      "learning_rate": 0.00010306532663316583,
      "loss": 0.7534,
      "step": 1950
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.21297422051429749,
      "learning_rate": 0.00010256281407035175,
      "loss": 0.6552,
      "step": 1960
    },
    {
      "epoch": 0.1576,
      "grad_norm": 0.23949193954467773,
      "learning_rate": 0.0001020603015075377,
      "loss": 0.7577,
      "step": 1970
    },
    {
      "epoch": 0.1584,
      "grad_norm": 0.1936357468366623,
      "learning_rate": 0.00010155778894472363,
      "loss": 0.64,
      "step": 1980
    },
    {
      "epoch": 0.1592,
      "grad_norm": 0.2544143497943878,
      "learning_rate": 0.00010105527638190955,
      "loss": 0.7787,
      "step": 1990
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.267303466796875,
      "learning_rate": 0.00010055276381909548,
      "loss": 0.7209,
      "step": 2000
    },
    {
      "epoch": 0.1608,
      "grad_norm": 0.19511152803897858,
      "learning_rate": 0.0001000502512562814,
      "loss": 0.7074,
      "step": 2010
    },
    {
      "epoch": 0.1616,
      "grad_norm": 0.25648921728134155,
      "learning_rate": 9.954773869346734e-05,
      "loss": 0.7432,
      "step": 2020
    },
    {
      "epoch": 0.1624,
      "grad_norm": 0.21235069632530212,
      "learning_rate": 9.904522613065326e-05,
      "loss": 0.7076,
      "step": 2030
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.22012794017791748,
      "learning_rate": 9.85427135678392e-05,
      "loss": 0.7659,
      "step": 2040
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.23559658229351044,
      "learning_rate": 9.804020100502513e-05,
      "loss": 0.6911,
      "step": 2050
    },
    {
      "epoch": 0.1648,
      "grad_norm": 0.20289745926856995,
      "learning_rate": 9.753768844221106e-05,
      "loss": 0.6535,
      "step": 2060
    },
    {
      "epoch": 0.1656,
      "grad_norm": 0.23819628357887268,
      "learning_rate": 9.703517587939699e-05,
      "loss": 0.7365,
      "step": 2070
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.22940152883529663,
      "learning_rate": 9.653266331658291e-05,
      "loss": 0.7875,
      "step": 2080
    },
    {
      "epoch": 0.1672,
      "grad_norm": 0.2074773758649826,
      "learning_rate": 9.603015075376884e-05,
      "loss": 0.7123,
      "step": 2090
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.20433233678340912,
      "learning_rate": 9.552763819095478e-05,
      "loss": 0.7239,
      "step": 2100
    },
    {
      "epoch": 0.1688,
      "grad_norm": 0.18349535763263702,
      "learning_rate": 9.502512562814071e-05,
      "loss": 0.6581,
      "step": 2110
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.2933589518070221,
      "learning_rate": 9.452261306532664e-05,
      "loss": 0.7846,
      "step": 2120
    },
    {
      "epoch": 0.1704,
      "grad_norm": 0.2039424628019333,
      "learning_rate": 9.402010050251256e-05,
      "loss": 0.7273,
      "step": 2130
    },
    {
      "epoch": 0.1712,
      "grad_norm": 0.24338167905807495,
      "learning_rate": 9.351758793969849e-05,
      "loss": 0.71,
      "step": 2140
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.20767468214035034,
      "learning_rate": 9.301507537688442e-05,
      "loss": 0.7855,
      "step": 2150
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.21796326339244843,
      "learning_rate": 9.251256281407036e-05,
      "loss": 0.6882,
      "step": 2160
    },
    {
      "epoch": 0.1736,
      "grad_norm": 0.2265208214521408,
      "learning_rate": 9.201005025125629e-05,
      "loss": 0.733,
      "step": 2170
    },
    {
      "epoch": 0.1744,
      "grad_norm": 0.19875019788742065,
      "learning_rate": 9.150753768844221e-05,
      "loss": 0.7102,
      "step": 2180
    },
    {
      "epoch": 0.1752,
      "grad_norm": 0.22943539917469025,
      "learning_rate": 9.100502512562814e-05,
      "loss": 0.6992,
      "step": 2190
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.2017524093389511,
      "learning_rate": 9.050251256281407e-05,
      "loss": 0.7388,
      "step": 2200
    },
    {
      "epoch": 0.1768,
      "grad_norm": 0.22363531589508057,
      "learning_rate": 9e-05,
      "loss": 0.7588,
      "step": 2210
    },
    {
      "epoch": 0.1776,
      "grad_norm": 0.26529914140701294,
      "learning_rate": 8.949748743718594e-05,
      "loss": 0.7141,
      "step": 2220
    },
    {
      "epoch": 0.1784,
      "grad_norm": 0.25501444935798645,
      "learning_rate": 8.899497487437186e-05,
      "loss": 0.7462,
      "step": 2230
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.17983761429786682,
      "learning_rate": 8.849246231155779e-05,
      "loss": 0.7827,
      "step": 2240
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.242720827460289,
      "learning_rate": 8.798994974874372e-05,
      "loss": 0.797,
      "step": 2250
    },
    {
      "epoch": 0.1808,
      "grad_norm": 0.19281144440174103,
      "learning_rate": 8.748743718592965e-05,
      "loss": 0.7461,
      "step": 2260
    },
    {
      "epoch": 0.1816,
      "grad_norm": 0.2173890769481659,
      "learning_rate": 8.698492462311559e-05,
      "loss": 0.7451,
      "step": 2270
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.25099048018455505,
      "learning_rate": 8.64824120603015e-05,
      "loss": 0.7687,
      "step": 2280
    },
    {
      "epoch": 0.1832,
      "grad_norm": 0.2695677876472473,
      "learning_rate": 8.597989949748744e-05,
      "loss": 0.7039,
      "step": 2290
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.23706293106079102,
      "learning_rate": 8.547738693467337e-05,
      "loss": 0.7339,
      "step": 2300
    },
    {
      "epoch": 0.1848,
      "grad_norm": 0.21112114191055298,
      "learning_rate": 8.49748743718593e-05,
      "loss": 0.7022,
      "step": 2310
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.23368991911411285,
      "learning_rate": 8.447236180904524e-05,
      "loss": 0.7496,
      "step": 2320
    },
    {
      "epoch": 0.1864,
      "grad_norm": 0.2323455512523651,
      "learning_rate": 8.396984924623115e-05,
      "loss": 0.7008,
      "step": 2330
    },
    {
      "epoch": 0.1872,
      "grad_norm": 0.30222639441490173,
      "learning_rate": 8.346733668341709e-05,
      "loss": 0.6994,
      "step": 2340
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.1718597263097763,
      "learning_rate": 8.296482412060302e-05,
      "loss": 0.6612,
      "step": 2350
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.2287936806678772,
      "learning_rate": 8.246231155778895e-05,
      "loss": 0.7807,
      "step": 2360
    },
    {
      "epoch": 0.1896,
      "grad_norm": 0.23257187008857727,
      "learning_rate": 8.195979899497488e-05,
      "loss": 0.7309,
      "step": 2370
    },
    {
      "epoch": 0.1904,
      "grad_norm": 0.2246100902557373,
      "learning_rate": 8.14572864321608e-05,
      "loss": 0.652,
      "step": 2380
    },
    {
      "epoch": 0.1912,
      "grad_norm": 0.22410403192043304,
      "learning_rate": 8.095477386934673e-05,
      "loss": 0.7458,
      "step": 2390
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.2894735336303711,
      "learning_rate": 8.045226130653267e-05,
      "loss": 0.7632,
      "step": 2400
    },
    {
      "epoch": 0.1928,
      "grad_norm": 0.25662338733673096,
      "learning_rate": 7.99497487437186e-05,
      "loss": 0.7008,
      "step": 2410
    },
    {
      "epoch": 0.1936,
      "grad_norm": 0.2435951828956604,
      "learning_rate": 7.944723618090453e-05,
      "loss": 0.7112,
      "step": 2420
    },
    {
      "epoch": 0.1944,
      "grad_norm": 0.18323855102062225,
      "learning_rate": 7.894472361809045e-05,
      "loss": 0.7044,
      "step": 2430
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.2287560999393463,
      "learning_rate": 7.844221105527638e-05,
      "loss": 0.6335,
      "step": 2440
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.23321683704853058,
      "learning_rate": 7.793969849246232e-05,
      "loss": 0.7124,
      "step": 2450
    },
    {
      "epoch": 0.1968,
      "grad_norm": 0.2891298532485962,
      "learning_rate": 7.743718592964825e-05,
      "loss": 0.7147,
      "step": 2460
    },
    {
      "epoch": 0.1976,
      "grad_norm": 0.35347527265548706,
      "learning_rate": 7.693467336683418e-05,
      "loss": 0.7715,
      "step": 2470
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.24558383226394653,
      "learning_rate": 7.64321608040201e-05,
      "loss": 0.7627,
      "step": 2480
    },
    {
      "epoch": 0.1992,
      "grad_norm": 0.26840144395828247,
      "learning_rate": 7.592964824120603e-05,
      "loss": 0.6989,
      "step": 2490
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.22185291349887848,
      "learning_rate": 7.542713567839196e-05,
      "loss": 0.6922,
      "step": 2500
    },
    {
      "epoch": 0.2008,
      "grad_norm": 0.2481534481048584,
      "learning_rate": 7.49246231155779e-05,
      "loss": 1.0439,
      "step": 2510
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.33817780017852783,
      "learning_rate": 7.442211055276383e-05,
      "loss": 0.9029,
      "step": 2520
    },
    {
      "epoch": 0.2024,
      "grad_norm": 0.21240876615047455,
      "learning_rate": 7.391959798994975e-05,
      "loss": 0.8902,
      "step": 2530
    },
    {
      "epoch": 0.2032,
      "grad_norm": 0.19108644127845764,
      "learning_rate": 7.341708542713568e-05,
      "loss": 0.8794,
      "step": 2540
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.21310953795909882,
      "learning_rate": 7.291457286432161e-05,
      "loss": 0.892,
      "step": 2550
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.27758413553237915,
      "learning_rate": 7.241206030150755e-05,
      "loss": 0.8838,
      "step": 2560
    },
    {
      "epoch": 0.2056,
      "grad_norm": 0.2165667861700058,
      "learning_rate": 7.190954773869348e-05,
      "loss": 0.7776,
      "step": 2570
    },
    {
      "epoch": 0.2064,
      "grad_norm": 0.2509649991989136,
      "learning_rate": 7.14070351758794e-05,
      "loss": 0.7661,
      "step": 2580
    },
    {
      "epoch": 0.2072,
      "grad_norm": 0.24190829694271088,
      "learning_rate": 7.090452261306533e-05,
      "loss": 0.7921,
      "step": 2590
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.2334054708480835,
      "learning_rate": 7.040201005025126e-05,
      "loss": 0.8084,
      "step": 2600
    },
    {
      "epoch": 0.2088,
      "grad_norm": 0.19128647446632385,
      "learning_rate": 6.98994974874372e-05,
      "loss": 0.8015,
      "step": 2610
    },
    {
      "epoch": 0.2096,
      "grad_norm": 0.19014257192611694,
      "learning_rate": 6.939698492462313e-05,
      "loss": 0.8142,
      "step": 2620
    },
    {
      "epoch": 0.2104,
      "grad_norm": 0.24523521959781647,
      "learning_rate": 6.889447236180905e-05,
      "loss": 0.8463,
      "step": 2630
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.1799396127462387,
      "learning_rate": 6.839195979899498e-05,
      "loss": 0.7908,
      "step": 2640
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.17529121041297913,
      "learning_rate": 6.78894472361809e-05,
      "loss": 0.7806,
      "step": 2650
    },
    {
      "epoch": 0.2128,
      "grad_norm": 0.22285237908363342,
      "learning_rate": 6.738693467336684e-05,
      "loss": 0.7562,
      "step": 2660
    },
    {
      "epoch": 0.2136,
      "grad_norm": 0.19359749555587769,
      "learning_rate": 6.688442211055277e-05,
      "loss": 0.737,
      "step": 2670
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.2549673914909363,
      "learning_rate": 6.63819095477387e-05,
      "loss": 0.8071,
      "step": 2680
    },
    {
      "epoch": 0.2152,
      "grad_norm": 0.22420406341552734,
      "learning_rate": 6.587939698492463e-05,
      "loss": 0.7472,
      "step": 2690
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.19433043897151947,
      "learning_rate": 6.537688442211054e-05,
      "loss": 0.7766,
      "step": 2700
    },
    {
      "epoch": 0.2168,
      "grad_norm": 0.18542368710041046,
      "learning_rate": 6.487437185929649e-05,
      "loss": 0.848,
      "step": 2710
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.2188122719526291,
      "learning_rate": 6.437185929648242e-05,
      "loss": 0.7932,
      "step": 2720
    },
    {
      "epoch": 0.2184,
      "grad_norm": 0.20450760424137115,
      "learning_rate": 6.386934673366834e-05,
      "loss": 0.7623,
      "step": 2730
    },
    {
      "epoch": 0.2192,
      "grad_norm": 0.2742721438407898,
      "learning_rate": 6.336683417085427e-05,
      "loss": 0.8453,
      "step": 2740
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.15745337307453156,
      "learning_rate": 6.28643216080402e-05,
      "loss": 0.6983,
      "step": 2750
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.19573111832141876,
      "learning_rate": 6.236180904522614e-05,
      "loss": 0.6844,
      "step": 2760
    },
    {
      "epoch": 0.2216,
      "grad_norm": 0.20490670204162598,
      "learning_rate": 6.185929648241207e-05,
      "loss": 0.7634,
      "step": 2770
    },
    {
      "epoch": 0.2224,
      "grad_norm": 0.21709831058979034,
      "learning_rate": 6.135678391959799e-05,
      "loss": 0.7959,
      "step": 2780
    },
    {
      "epoch": 0.2232,
      "grad_norm": 0.15011802315711975,
      "learning_rate": 6.085427135678392e-05,
      "loss": 0.7633,
      "step": 2790
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.22854948043823242,
      "learning_rate": 6.035175879396985e-05,
      "loss": 0.7528,
      "step": 2800
    },
    {
      "epoch": 0.2248,
      "grad_norm": 0.27997446060180664,
      "learning_rate": 5.984924623115579e-05,
      "loss": 0.7814,
      "step": 2810
    },
    {
      "epoch": 0.2256,
      "grad_norm": 0.19721448421478271,
      "learning_rate": 5.9346733668341714e-05,
      "loss": 0.802,
      "step": 2820
    },
    {
      "epoch": 0.2264,
      "grad_norm": 0.14591050148010254,
      "learning_rate": 5.884422110552764e-05,
      "loss": 0.7571,
      "step": 2830
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.2143571376800537,
      "learning_rate": 5.834170854271357e-05,
      "loss": 0.841,
      "step": 2840
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.22955183684825897,
      "learning_rate": 5.78391959798995e-05,
      "loss": 0.7639,
      "step": 2850
    },
    {
      "epoch": 0.2288,
      "grad_norm": 0.19173507392406464,
      "learning_rate": 5.7336683417085437e-05,
      "loss": 0.7385,
      "step": 2860
    },
    {
      "epoch": 0.2296,
      "grad_norm": 0.21304017305374146,
      "learning_rate": 5.683417085427136e-05,
      "loss": 0.7709,
      "step": 2870
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.17785318195819855,
      "learning_rate": 5.633165829145729e-05,
      "loss": 0.8142,
      "step": 2880
    },
    {
      "epoch": 0.2312,
      "grad_norm": 0.2088308334350586,
      "learning_rate": 5.582914572864322e-05,
      "loss": 0.828,
      "step": 2890
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.16119718551635742,
      "learning_rate": 5.5326633165829146e-05,
      "loss": 0.7549,
      "step": 2900
    },
    {
      "epoch": 0.2328,
      "grad_norm": 0.2429371178150177,
      "learning_rate": 5.4824120603015085e-05,
      "loss": 0.7827,
      "step": 2910
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.19972702860832214,
      "learning_rate": 5.432160804020101e-05,
      "loss": 0.7676,
      "step": 2920
    },
    {
      "epoch": 0.2344,
      "grad_norm": 0.19166086614131927,
      "learning_rate": 5.3819095477386936e-05,
      "loss": 0.6848,
      "step": 2930
    },
    {
      "epoch": 0.2352,
      "grad_norm": 0.21792283654212952,
      "learning_rate": 5.331658291457287e-05,
      "loss": 0.7797,
      "step": 2940
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.19781868159770966,
      "learning_rate": 5.2814070351758794e-05,
      "loss": 0.8189,
      "step": 2950
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.18459826707839966,
      "learning_rate": 5.231155778894472e-05,
      "loss": 0.7796,
      "step": 2960
    },
    {
      "epoch": 0.2376,
      "grad_norm": 0.2070247083902359,
      "learning_rate": 5.180904522613066e-05,
      "loss": 0.7387,
      "step": 2970
    },
    {
      "epoch": 0.2384,
      "grad_norm": 0.21528781950473785,
      "learning_rate": 5.1306532663316585e-05,
      "loss": 0.8003,
      "step": 2980
    },
    {
      "epoch": 0.2392,
      "grad_norm": 0.2478795051574707,
      "learning_rate": 5.080402010050252e-05,
      "loss": 0.7982,
      "step": 2990
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.18887469172477722,
      "learning_rate": 5.030150753768844e-05,
      "loss": 0.7999,
      "step": 3000
    },
    {
      "epoch": 0.2408,
      "grad_norm": 0.18132023513317108,
      "learning_rate": 4.9798994974874375e-05,
      "loss": 0.701,
      "step": 3010
    },
    {
      "epoch": 0.2416,
      "grad_norm": 0.15265551209449768,
      "learning_rate": 4.92964824120603e-05,
      "loss": 0.7021,
      "step": 3020
    },
    {
      "epoch": 0.2424,
      "grad_norm": 0.18712344765663147,
      "learning_rate": 4.8793969849246233e-05,
      "loss": 0.7981,
      "step": 3030
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.2527002990245819,
      "learning_rate": 4.829145728643216e-05,
      "loss": 0.7423,
      "step": 3040
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.2340082973241806,
      "learning_rate": 4.77889447236181e-05,
      "loss": 0.813,
      "step": 3050
    },
    {
      "epoch": 0.2448,
      "grad_norm": 0.22979189455509186,
      "learning_rate": 4.7286432160804024e-05,
      "loss": 0.7521,
      "step": 3060
    },
    {
      "epoch": 0.2456,
      "grad_norm": 0.22312836349010468,
      "learning_rate": 4.678391959798995e-05,
      "loss": 0.706,
      "step": 3070
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.1896573305130005,
      "learning_rate": 4.628140703517588e-05,
      "loss": 0.718,
      "step": 3080
    },
    {
      "epoch": 0.2472,
      "grad_norm": 0.2013261318206787,
      "learning_rate": 4.577889447236181e-05,
      "loss": 0.7209,
      "step": 3090
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.1828044354915619,
      "learning_rate": 4.527638190954774e-05,
      "loss": 0.6788,
      "step": 3100
    },
    {
      "epoch": 0.2488,
      "grad_norm": 0.1712699830532074,
      "learning_rate": 4.477386934673367e-05,
      "loss": 0.782,
      "step": 3110
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.1995314210653305,
      "learning_rate": 4.42713567839196e-05,
      "loss": 0.7979,
      "step": 3120
    },
    {
      "epoch": 0.2504,
      "grad_norm": 0.17471908032894135,
      "learning_rate": 4.376884422110553e-05,
      "loss": 0.825,
      "step": 3130
    },
    {
      "epoch": 0.2512,
      "grad_norm": 0.1884690523147583,
      "learning_rate": 4.3266331658291456e-05,
      "loss": 0.6903,
      "step": 3140
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.2028089463710785,
      "learning_rate": 4.276381909547739e-05,
      "loss": 0.6735,
      "step": 3150
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.18137754499912262,
      "learning_rate": 4.226130653266332e-05,
      "loss": 0.6908,
      "step": 3160
    },
    {
      "epoch": 0.2536,
      "grad_norm": 0.18288995325565338,
      "learning_rate": 4.1758793969849247e-05,
      "loss": 0.7223,
      "step": 3170
    },
    {
      "epoch": 0.2544,
      "grad_norm": 0.23011431097984314,
      "learning_rate": 4.125628140703518e-05,
      "loss": 0.7875,
      "step": 3180
    },
    {
      "epoch": 0.2552,
      "grad_norm": 0.16320304572582245,
      "learning_rate": 4.0753768844221105e-05,
      "loss": 0.7159,
      "step": 3190
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.15154629945755005,
      "learning_rate": 4.025125628140704e-05,
      "loss": 0.762,
      "step": 3200
    },
    {
      "epoch": 0.2568,
      "grad_norm": 0.22517633438110352,
      "learning_rate": 3.974874371859297e-05,
      "loss": 0.7414,
      "step": 3210
    },
    {
      "epoch": 0.2576,
      "grad_norm": 0.25593283772468567,
      "learning_rate": 3.9246231155778895e-05,
      "loss": 0.7093,
      "step": 3220
    },
    {
      "epoch": 0.2584,
      "grad_norm": 0.2485640048980713,
      "learning_rate": 3.874371859296483e-05,
      "loss": 0.7867,
      "step": 3230
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.17446322739124298,
      "learning_rate": 3.824120603015075e-05,
      "loss": 0.8169,
      "step": 3240
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2101462185382843,
      "learning_rate": 3.7738693467336686e-05,
      "loss": 0.7283,
      "step": 3250
    },
    {
      "epoch": 0.2608,
      "grad_norm": 0.44385942816734314,
      "learning_rate": 3.723618090452262e-05,
      "loss": 0.7776,
      "step": 3260
    },
    {
      "epoch": 0.2616,
      "grad_norm": 0.21020856499671936,
      "learning_rate": 3.6733668341708544e-05,
      "loss": 0.7224,
      "step": 3270
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.17725743353366852,
      "learning_rate": 3.6231155778894476e-05,
      "loss": 0.7383,
      "step": 3280
    },
    {
      "epoch": 0.2632,
      "grad_norm": 0.18593832850456238,
      "learning_rate": 3.57286432160804e-05,
      "loss": 0.721,
      "step": 3290
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.2659083306789398,
      "learning_rate": 3.5226130653266334e-05,
      "loss": 0.7018,
      "step": 3300
    },
    {
      "epoch": 0.2648,
      "grad_norm": 0.20592401921749115,
      "learning_rate": 3.4723618090452267e-05,
      "loss": 0.6494,
      "step": 3310
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.22365286946296692,
      "learning_rate": 3.422110552763819e-05,
      "loss": 0.7786,
      "step": 3320
    },
    {
      "epoch": 0.2664,
      "grad_norm": 0.2509438693523407,
      "learning_rate": 3.371859296482412e-05,
      "loss": 0.8137,
      "step": 3330
    },
    {
      "epoch": 0.2672,
      "grad_norm": 0.2189168483018875,
      "learning_rate": 3.321608040201005e-05,
      "loss": 0.7737,
      "step": 3340
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.2545386850833893,
      "learning_rate": 3.271356783919598e-05,
      "loss": 0.8236,
      "step": 3350
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.2883812487125397,
      "learning_rate": 3.2211055276381915e-05,
      "loss": 0.8189,
      "step": 3360
    },
    {
      "epoch": 0.2696,
      "grad_norm": 0.19694764912128448,
      "learning_rate": 3.170854271356784e-05,
      "loss": 0.811,
      "step": 3370
    },
    {
      "epoch": 0.2704,
      "grad_norm": 0.24616701900959015,
      "learning_rate": 3.1206030150753766e-05,
      "loss": 0.8036,
      "step": 3380
    },
    {
      "epoch": 0.2712,
      "grad_norm": 0.21469056606292725,
      "learning_rate": 3.07035175879397e-05,
      "loss": 0.74,
      "step": 3390
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.21014556288719177,
      "learning_rate": 3.0201005025125628e-05,
      "loss": 0.7,
      "step": 3400
    },
    {
      "epoch": 0.2728,
      "grad_norm": 0.21513767540454865,
      "learning_rate": 2.969849246231156e-05,
      "loss": 0.7079,
      "step": 3410
    },
    {
      "epoch": 0.2736,
      "grad_norm": 0.24045424163341522,
      "learning_rate": 2.919597989949749e-05,
      "loss": 0.7999,
      "step": 3420
    },
    {
      "epoch": 0.2744,
      "grad_norm": 0.2095135599374771,
      "learning_rate": 2.8693467336683415e-05,
      "loss": 0.7793,
      "step": 3430
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.17638809978961945,
      "learning_rate": 2.819095477386935e-05,
      "loss": 0.8639,
      "step": 3440
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.18506285548210144,
      "learning_rate": 2.7688442211055276e-05,
      "loss": 0.7443,
      "step": 3450
    },
    {
      "epoch": 0.2768,
      "grad_norm": 0.18190085887908936,
      "learning_rate": 2.718592964824121e-05,
      "loss": 0.7707,
      "step": 3460
    },
    {
      "epoch": 0.2776,
      "grad_norm": 0.2230578511953354,
      "learning_rate": 2.6683417085427138e-05,
      "loss": 0.7363,
      "step": 3470
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.2007257044315338,
      "learning_rate": 2.6180904522613063e-05,
      "loss": 0.8209,
      "step": 3480
    },
    {
      "epoch": 0.2792,
      "grad_norm": 0.22891375422477722,
      "learning_rate": 2.5678391959798996e-05,
      "loss": 0.7502,
      "step": 3490
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.2160113900899887,
      "learning_rate": 2.5175879396984925e-05,
      "loss": 0.7454,
      "step": 3500
    },
    {
      "epoch": 0.2808,
      "grad_norm": 0.18476897478103638,
      "learning_rate": 2.4673366834170854e-05,
      "loss": 0.7456,
      "step": 3510
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.2364911437034607,
      "learning_rate": 2.4170854271356786e-05,
      "loss": 0.7749,
      "step": 3520
    },
    {
      "epoch": 0.2824,
      "grad_norm": 0.18886782228946686,
      "learning_rate": 2.3668341708542715e-05,
      "loss": 0.7314,
      "step": 3530
    },
    {
      "epoch": 0.2832,
      "grad_norm": 0.18824386596679688,
      "learning_rate": 2.3165829145728644e-05,
      "loss": 0.744,
      "step": 3540
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.1724703162908554,
      "learning_rate": 2.2663316582914573e-05,
      "loss": 0.7066,
      "step": 3550
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.2143459916114807,
      "learning_rate": 2.2160804020100502e-05,
      "loss": 0.8034,
      "step": 3560
    },
    {
      "epoch": 0.2856,
      "grad_norm": 0.18534216284751892,
      "learning_rate": 2.1658291457286435e-05,
      "loss": 0.8038,
      "step": 3570
    },
    {
      "epoch": 0.2864,
      "grad_norm": 0.21237538754940033,
      "learning_rate": 2.1155778894472364e-05,
      "loss": 0.7408,
      "step": 3580
    },
    {
      "epoch": 0.2872,
      "grad_norm": 0.24253103137016296,
      "learning_rate": 2.0653266331658293e-05,
      "loss": 0.7743,
      "step": 3590
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.24066311120986938,
      "learning_rate": 2.0150753768844222e-05,
      "loss": 0.7736,
      "step": 3600
    },
    {
      "epoch": 0.2888,
      "grad_norm": 0.3023224174976349,
      "learning_rate": 1.964824120603015e-05,
      "loss": 0.8095,
      "step": 3610
    },
    {
      "epoch": 0.2896,
      "grad_norm": 0.23907038569450378,
      "learning_rate": 1.9145728643216083e-05,
      "loss": 0.7633,
      "step": 3620
    },
    {
      "epoch": 0.2904,
      "grad_norm": 0.17987923324108124,
      "learning_rate": 1.8643216080402012e-05,
      "loss": 0.7688,
      "step": 3630
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.23963706195354462,
      "learning_rate": 1.814070351758794e-05,
      "loss": 0.7261,
      "step": 3640
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.19149167835712433,
      "learning_rate": 1.763819095477387e-05,
      "loss": 0.742,
      "step": 3650
    },
    {
      "epoch": 0.2928,
      "grad_norm": 0.15501797199249268,
      "learning_rate": 1.71356783919598e-05,
      "loss": 0.707,
      "step": 3660
    },
    {
      "epoch": 0.2936,
      "grad_norm": 0.19567610323429108,
      "learning_rate": 1.6633165829145732e-05,
      "loss": 0.7802,
      "step": 3670
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.23044496774673462,
      "learning_rate": 1.6130653266331658e-05,
      "loss": 0.7319,
      "step": 3680
    },
    {
      "epoch": 0.2952,
      "grad_norm": 0.18427325785160065,
      "learning_rate": 1.5628140703517587e-05,
      "loss": 0.7595,
      "step": 3690
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.24563740193843842,
      "learning_rate": 1.5125628140703519e-05,
      "loss": 0.7928,
      "step": 3700
    },
    {
      "epoch": 0.2968,
      "grad_norm": 0.23160748183727264,
      "learning_rate": 1.4623115577889448e-05,
      "loss": 0.8101,
      "step": 3710
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.27244284749031067,
      "learning_rate": 1.4120603015075379e-05,
      "loss": 0.7229,
      "step": 3720
    },
    {
      "epoch": 0.2984,
      "grad_norm": 0.2126634120941162,
      "learning_rate": 1.3618090452261306e-05,
      "loss": 0.7286,
      "step": 3730
    },
    {
      "epoch": 0.2992,
      "grad_norm": 0.26530614495277405,
      "learning_rate": 1.3115577889447237e-05,
      "loss": 0.73,
      "step": 3740
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.2139672040939331,
      "learning_rate": 1.2613065326633166e-05,
      "loss": 0.7726,
      "step": 3750
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.19354085624217987,
      "learning_rate": 1.2110552763819095e-05,
      "loss": 0.7779,
      "step": 3760
    },
    {
      "epoch": 0.3016,
      "grad_norm": 0.23887565732002258,
      "learning_rate": 1.1608040201005026e-05,
      "loss": 0.7433,
      "step": 3770
    },
    {
      "epoch": 0.3024,
      "grad_norm": 0.17293651401996613,
      "learning_rate": 1.1105527638190956e-05,
      "loss": 0.712,
      "step": 3780
    },
    {
      "epoch": 0.3032,
      "grad_norm": 0.17907093465328217,
      "learning_rate": 1.0603015075376885e-05,
      "loss": 0.6928,
      "step": 3790
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.1790967434644699,
      "learning_rate": 1.0100502512562814e-05,
      "loss": 0.7108,
      "step": 3800
    },
    {
      "epoch": 0.3048,
      "grad_norm": 0.22262154519557953,
      "learning_rate": 9.597989949748743e-06,
      "loss": 0.7469,
      "step": 3810
    },
    {
      "epoch": 0.3056,
      "grad_norm": 0.210264652967453,
      "learning_rate": 9.095477386934674e-06,
      "loss": 0.8099,
      "step": 3820
    },
    {
      "epoch": 0.3064,
      "grad_norm": 0.21513661742210388,
      "learning_rate": 8.592964824120603e-06,
      "loss": 0.7605,
      "step": 3830
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.2485332489013672,
      "learning_rate": 8.090452261306534e-06,
      "loss": 0.7285,
      "step": 3840
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.1928872913122177,
      "learning_rate": 7.587939698492464e-06,
      "loss": 0.7568,
      "step": 3850
    },
    {
      "epoch": 0.3088,
      "grad_norm": 0.1671837717294693,
      "learning_rate": 7.085427135678392e-06,
      "loss": 0.8034,
      "step": 3860
    },
    {
      "epoch": 0.3096,
      "grad_norm": 0.18609841167926788,
      "learning_rate": 6.582914572864323e-06,
      "loss": 0.7314,
      "step": 3870
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.20463094115257263,
      "learning_rate": 6.080402010050252e-06,
      "loss": 0.7607,
      "step": 3880
    },
    {
      "epoch": 0.3112,
      "grad_norm": 0.219449982047081,
      "learning_rate": 5.5778894472361815e-06,
      "loss": 0.7175,
      "step": 3890
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.195594921708107,
      "learning_rate": 5.075376884422111e-06,
      "loss": 0.7361,
      "step": 3900
    }
  ],
  "logging_steps": 10,
  "max_steps": 4000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.641712406522675e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
